{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from google.colab import drive\n",
    "from keras.utils.traceback_utils import include_frame\n",
    "\n",
    "tensorflow.random.set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open zip in google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = 'drive/MyDrive/datasets/data.zip'\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import EDA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "#                ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "# Classification:           1           2        3           4          5        6              7               8\n",
    "def merge_animals(df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    df_copy = df.copy() # copy df\n",
    "    columns = df_copy.columns # get column names\n",
    "    df_copy['animal_classification'] = np.where(df_copy.values)[1]+1 # add a numeric value to each column\n",
    "    df_copy.drop(columns ,axis=1, inplace=True) # drop columns that were just combined\n",
    "    return df_copy\n",
    "\n",
    "def plot_metrics(model_fit):\n",
    "    metrics = ['accuracy', 'precision', 'recall']\n",
    "    for i in metrics:\n",
    "        plt.plot(model_fit.history[i], label='Train')\n",
    "        plt.plot(model_fit.history[f'val_{i}'], label='Test')\n",
    "        plt.ylabel(i)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('data/test_features.csv')\n",
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "train = pd.merge(left=train_features, right=train_labels, on='id') # combine df's and the right answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Validation And Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train df's on id\n",
    "train = pd.merge(left=train_features, right=train_labels, on='id') \n",
    "\n",
    "# see function in above cell\n",
    "train['animal_classification'] = merge_animals(train[['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']]) \n",
    "# done in function above ^ might need \n",
    "# train.drop(['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent'] ,axis=1, inplace=True) # drop\n",
    "\n",
    "# rename numeric observations to actual classifications\n",
    "train['animal_classification'] = train['animal_classification'].map({1:'antelope_duiker', 2:'bird', 3:'blank', 4:'civet_genet', 5:'hog', 6:'leopard', 7:'monkey_prosimian', 8:'rodent'})\n",
    "\n",
    "# split file path column to get file names\n",
    "temp = train['filepath'].str.split(pat='/',expand=True)\n",
    "# rename split columns\n",
    "temp.rename(columns={0: 'old_folder_location', 1: 'filename'}, inplace=True)\n",
    "\n",
    "# concat columns and original df\n",
    "train = pd.concat([train, temp], axis=1).drop(columns=['filepath'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make validation set\n",
    "validation_set = train[(train['site']=='S0009') | (train['site']=='S0043')| (train['site']=='S0059') |(train['site']== 'S0026')] # get validation set for 2 sites\n",
    "# make training set\n",
    "train_set = train[~train.isin(validation_set)].dropna() # remove the observations from train that are in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set['animal_classification'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train_features_img/'\n",
    "test_path = 'data/test_features_img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image Gen stuff\n",
    "img_gen = ImageDataGenerator(\n",
    "        # brightness_range=[.4, 1.2],\n",
    ")\n",
    "val_generator = img_gen.flow_from_dataframe(\n",
    "    validation_set, \n",
    "    directory=train_path, \n",
    "    x_col='filename', \n",
    "    y_col='animal_classification', \n",
    "    target_size=(256, 256), \n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "train_generator = img_gen.flow_from_dataframe(\n",
    "    train_set, \n",
    "    directory=train_path, \n",
    "    x_col='filename', \n",
    "    y_col='animal_classification', \n",
    "    target_size=(256, 256), \n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# layers\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy', 'Recall', 'Precision'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
