{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.losses import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('./data/test_features.csv')\n",
    "train_features = pd.read_csv('./data/train_features.csv')\n",
    "train_labels = pd.read_csv('./data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJ000000</td>\n",
       "      <td>train_features/ZJ000000.jpg</td>\n",
       "      <td>S0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJ000001</td>\n",
       "      <td>train_features/ZJ000001.jpg</td>\n",
       "      <td>S0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJ000002</td>\n",
       "      <td>train_features/ZJ000002.jpg</td>\n",
       "      <td>S0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJ000003</td>\n",
       "      <td>train_features/ZJ000003.jpg</td>\n",
       "      <td>S0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJ000004</td>\n",
       "      <td>train_features/ZJ000004.jpg</td>\n",
       "      <td>S0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16483</th>\n",
       "      <td>ZJ016483</td>\n",
       "      <td>train_features/ZJ016483.jpg</td>\n",
       "      <td>S0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16484</th>\n",
       "      <td>ZJ016484</td>\n",
       "      <td>train_features/ZJ016484.jpg</td>\n",
       "      <td>S0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16485</th>\n",
       "      <td>ZJ016485</td>\n",
       "      <td>train_features/ZJ016485.jpg</td>\n",
       "      <td>S0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>ZJ016486</td>\n",
       "      <td>train_features/ZJ016486.jpg</td>\n",
       "      <td>S0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>ZJ016487</td>\n",
       "      <td>train_features/ZJ016487.jpg</td>\n",
       "      <td>S0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16488 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                     filepath   site\n",
       "0      ZJ000000  train_features/ZJ000000.jpg  S0120\n",
       "1      ZJ000001  train_features/ZJ000001.jpg  S0069\n",
       "2      ZJ000002  train_features/ZJ000002.jpg  S0009\n",
       "3      ZJ000003  train_features/ZJ000003.jpg  S0008\n",
       "4      ZJ000004  train_features/ZJ000004.jpg  S0036\n",
       "...         ...                          ...    ...\n",
       "16483  ZJ016483  train_features/ZJ016483.jpg  S0093\n",
       "16484  ZJ016484  train_features/ZJ016484.jpg  S0043\n",
       "16485  ZJ016485  train_features/ZJ016485.jpg  S0089\n",
       "16486  ZJ016486  train_features/ZJ016486.jpg  S0095\n",
       "16487  ZJ016487  train_features/ZJ016487.jpg  S0021\n",
       "\n",
       "[16488 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_animals(df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    df_copy = df.copy() # copy df\n",
    "    columns = df_copy.columns # get column names\n",
    "    df_copy['animal_classification'] = np.where(df_copy.values)[1]+1 # add a numeric value to each column\n",
    "    df_copy.drop(columns ,axis=1, inplace=True) # drop columns that were just combined\n",
    "    return df_copy\n",
    "#                ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "# Classification:           1           2        3           4          5        6              7               8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train df's on id\n",
    "train = pd.merge(left=train_features, right=train_labels, on='id') \n",
    "\n",
    "# see function in above cell\n",
    "train['animal_classification'] = merge_animals(train[['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']]) \n",
    "# done in function above ^ might need \n",
    "# train.drop(['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent'] ,axis=1, inplace=True) # drop\n",
    "\n",
    "# rename numeric observations to actual classifications\n",
    "train['animal_classification'] = train['animal_classification'].map({1:'antelope_duiker', 2:'bird', 3:'blank', 4:'civet_genet', 5:'hog', 6:'leopard', 7:'monkey_prosimian', 8:'rodent'})\n",
    "\n",
    "# split file path column to get file names\n",
    "temp = train['filepath'].str.split(pat='/',expand=True)\n",
    "# rename split columns\n",
    "temp.rename(columns={0: 'old_folder_location', 1: 'filename'}, inplace=True)\n",
    "\n",
    "# concat columns and original df\n",
    "train = pd.concat([train, temp], axis=1).drop(columns=['filepath'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civet_genet         959\n",
      "antelope_duiker      59\n",
      "monkey_prosimian     49\n",
      "blank                23\n",
      "rodent               22\n",
      "hog                  20\n",
      "Name: animal_classification, dtype: int64\n",
      "monkey_prosimian    190\n",
      "hog                 188\n",
      "bird                155\n",
      "blank                57\n",
      "antelope_duiker      33\n",
      "rodent               25\n",
      "civet_genet          16\n",
      "Name: animal_classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# finding better site number that are more balanced\n",
    "print(train[train['site'] == 'S0060']['animal_classification'].value_counts())\n",
    "print(train[train['site'] == 'S0009']['animal_classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make validation set\n",
    "validation_set = train[(train['site']=='S0009') | (train['site']=='S0043')| (train['site']=='S0059') |(train['site']== 'S0026')] # get validation set for 2 sites\n",
    "# make training set\n",
    "train_set = train[~train.isin(validation_set)].dropna() # remove the observations from train that are in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0009    0.402424\n",
      "S0043    0.269091\n",
      "S0059    0.265455\n",
      "S0026    0.063030\n",
      "Name: site, dtype: float64\n",
      "S0060    0.076291\n",
      "S0063    0.037539\n",
      "S0008    0.036460\n",
      "S0036    0.030732\n",
      "S0038    0.028912\n",
      "           ...   \n",
      "S0143    0.000202\n",
      "S0078    0.000135\n",
      "S0079    0.000135\n",
      "S0178    0.000135\n",
      "S0102    0.000067\n",
      "Name: site, Length: 144, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(validation_set['site'].value_counts(normalize=True))\n",
    "print(train_set['site'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1650 validated image filenames belonging to 8 classes.\n",
      "Found 14838 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# image Gen stuff\n",
    "# ['antelope_duiker',\t'bird',\t'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian','rodent']\n",
    "train_path = './data/train_features_img'\n",
    "img_gen = ImageDataGenerator()\n",
    "val_generator = img_gen.flow_from_dataframe(\n",
    "    validation_set, \n",
    "    directory=train_path, \n",
    "    x_col='filename', \n",
    "    y_col='animal_classification', \n",
    "    target_size=(256, 256), \n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")\n",
    "train_generator = img_gen.flow_from_dataframe(\n",
    "    train_set, \n",
    "    directory=train_path, \n",
    "    x_col='filename', \n",
    "    y_col='animal_classification', \n",
    "    target_size=(256, 256), \n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(model_fit):\n",
    "    metrics = ['accuracy', 'precision', 'recall']\n",
    "    for i in metrics:\n",
    "        plt.plot(model_fit.history[i], label='Train')\n",
    "        plt.plot(model_fit.history[f'val_{i}'], label='Test')\n",
    "        plt.ylabel(i)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 10:28:39.309714: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# layers\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(units=8, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1e6c26adc8bad395b004c18f56e59eec4f16088a73327fc7833d1c5c445ad10"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DL_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
