{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "colab = False  # Type True if using Google Colab, type False if using Jupyter Notebook\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mounting Google Drive for use with Google Colab\n",
    "if colab:\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating file paths for use with Google Colab\n",
    "if colab:\n",
    "    train_features_path = 'drive/MyDrive/group_project_data/Train-Features/train_features copy.csv'\n",
    "    train_labels_path = 'drive/MyDrive/group_project_data/Train-Label/train_labels copy.csv'\n",
    "    test_features_path = 'drive/MyDrive/group_project_data/Test-Features/test_features copy.csv'\n",
    "    train_images_path = 'drive/MyDrive/group_project_data/Train-Images/train_features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrames from csv files\n",
    "if colab:\n",
    "    train_features = pd.read_csv(train_features_path)\n",
    "    train_labels = pd.read_csv(train_labels_path)\n",
    "    test_features = pd.read_csv(test_features_path)\n",
    "else:\n",
    "    train_features = pd.read_csv('./data/train_features.csv')\n",
    "    train_labels = pd.read_csv('./data/train_labels.csv')\n",
    "    test_features = pd.read_csv('./data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJ000000</td>\n",
       "      <td>train_features/ZJ000000.jpg</td>\n",
       "      <td>S0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJ000001</td>\n",
       "      <td>train_features/ZJ000001.jpg</td>\n",
       "      <td>S0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJ000002</td>\n",
       "      <td>train_features/ZJ000002.jpg</td>\n",
       "      <td>S0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJ000003</td>\n",
       "      <td>train_features/ZJ000003.jpg</td>\n",
       "      <td>S0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJ000004</td>\n",
       "      <td>train_features/ZJ000004.jpg</td>\n",
       "      <td>S0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16483</th>\n",
       "      <td>ZJ016483</td>\n",
       "      <td>train_features/ZJ016483.jpg</td>\n",
       "      <td>S0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16484</th>\n",
       "      <td>ZJ016484</td>\n",
       "      <td>train_features/ZJ016484.jpg</td>\n",
       "      <td>S0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16485</th>\n",
       "      <td>ZJ016485</td>\n",
       "      <td>train_features/ZJ016485.jpg</td>\n",
       "      <td>S0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>ZJ016486</td>\n",
       "      <td>train_features/ZJ016486.jpg</td>\n",
       "      <td>S0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>ZJ016487</td>\n",
       "      <td>train_features/ZJ016487.jpg</td>\n",
       "      <td>S0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16488 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                     filepath   site\n",
       "0      ZJ000000  train_features/ZJ000000.jpg  S0120\n",
       "1      ZJ000001  train_features/ZJ000001.jpg  S0069\n",
       "2      ZJ000002  train_features/ZJ000002.jpg  S0009\n",
       "3      ZJ000003  train_features/ZJ000003.jpg  S0008\n",
       "4      ZJ000004  train_features/ZJ000004.jpg  S0036\n",
       "...         ...                          ...    ...\n",
       "16483  ZJ016483  train_features/ZJ016483.jpg  S0093\n",
       "16484  ZJ016484  train_features/ZJ016484.jpg  S0043\n",
       "16485  ZJ016485  train_features/ZJ016485.jpg  S0089\n",
       "16486  ZJ016486  train_features/ZJ016486.jpg  S0095\n",
       "16487  ZJ016487  train_features/ZJ016487.jpg  S0021\n",
       "\n",
       "[16488 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_animals(df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    df_copy = df.copy() # copy df\n",
    "    columns = df_copy.columns # get column names\n",
    "    df_copy['animal_classification'] = np.where(df_copy.values)[1]+1 # add a numeric value to each column\n",
    "    df_copy.drop(columns ,axis=1, inplace=True) # drop columns that were just combined\n",
    "    return df_copy\n",
    "#                ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "# Classification:           1           2        3           4          5        6              7               8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train df's on id\n",
    "train = pd.merge(left=train_features, right=train_labels, on='id') \n",
    "\n",
    "# see function in above cell\n",
    "train['animal_classification'] = merge_animals(train[['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']]) \n",
    "# done in function above ^ might need \n",
    "# train.drop(['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent'] ,axis=1, inplace=True) # drop\n",
    "\n",
    "# rename numeric observations to actual classifications\n",
    "train['animal_classification'] = train['animal_classification'].map({1:'antelope_duiker', 2:'bird', 3:'blank', 4:'civet_genet', 5:'hog', 6:'leopard', 7:'monkey_prosimian', 8:'rodent'})\n",
    "\n",
    "# split file path column to get file names\n",
    "temp = train['filepath'].str.split(pat='/',expand=True)\n",
    "# rename split columns\n",
    "temp.rename(columns={0: 'old_folder_location', 1: 'filename'}, inplace=True)\n",
    "\n",
    "# concat columns and original df\n",
    "train = pd.concat([train, temp], axis=1).drop(columns=['filepath'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civet_genet         959\n",
      "antelope_duiker      59\n",
      "monkey_prosimian     49\n",
      "blank                23\n",
      "rodent               22\n",
      "hog                  20\n",
      "Name: animal_classification, dtype: int64\n",
      "monkey_prosimian    190\n",
      "hog                 188\n",
      "bird                155\n",
      "blank                57\n",
      "antelope_duiker      33\n",
      "rodent               25\n",
      "civet_genet          16\n",
      "Name: animal_classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# finding better site number that are more balanced\n",
    "print(train[train['site'] == 'S0060']['animal_classification'].value_counts())\n",
    "print(train[train['site'] == 'S0009']['animal_classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make validation set\n",
    "validation_set = train[(train['site']=='S0009') | (train['site']=='S0043')| (train['site']=='S0059') |(train['site']== 'S0026')] # get validation set for 2 sites\n",
    "# make training set\n",
    "train_set = train[~train.isin(validation_set)].dropna() # remove the observations from train that are in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0009    0.402424\n",
      "S0043    0.269091\n",
      "S0059    0.265455\n",
      "S0026    0.063030\n",
      "Name: site, dtype: float64\n",
      "S0060    0.076291\n",
      "S0063    0.037539\n",
      "S0008    0.036460\n",
      "S0036    0.030732\n",
      "S0038    0.028912\n",
      "           ...   \n",
      "S0143    0.000202\n",
      "S0078    0.000135\n",
      "S0079    0.000135\n",
      "S0178    0.000135\n",
      "S0102    0.000067\n",
      "Name: site, Length: 144, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(validation_set['site'].value_counts(normalize=True))\n",
    "print(train_set['site'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1650 validated image filenames belonging to 8 classes.\n",
      "Found 14838 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating an ImageDataGenerator\n",
    "if colab:\n",
    "    img_gen = ImageDataGenerator()\n",
    "    val_generator = img_gen.flow_from_dataframe(\n",
    "        validation_set, \n",
    "        directory=train_images_path, \n",
    "        x_col='filename', \n",
    "        y_col='animal_classification', \n",
    "        target_size=(256, 256), \n",
    "        class_mode='categorical',\n",
    "        batch_size=32\n",
    ")\n",
    "    train_generator = img_gen.flow_from_dataframe(\n",
    "        train_set, \n",
    "        directory=train_images_path, \n",
    "        x_col='filename', \n",
    "        y_col='animal_classification', \n",
    "        target_size=(256, 256), \n",
    "        class_mode='categorical',\n",
    "        batch_size=64\n",
    ")\n",
    "else:\n",
    "    img_gen = ImageDataGenerator()\n",
    "    val_generator = img_gen.flow_from_dataframe(\n",
    "        validation_set, \n",
    "        directory='./data/train_features_img', \n",
    "        x_col='filename', \n",
    "        y_col='animal_classification', \n",
    "        target_size=(256, 256), \n",
    "        class_mode='categorical',\n",
    "        batch_size=32\n",
    ")\n",
    "    train_generator = img_gen.flow_from_dataframe(\n",
    "        train_set, \n",
    "        directory='./data/train_features_img', \n",
    "        x_col='filename', \n",
    "        y_col='animal_classification', \n",
    "        target_size=(256, 256), \n",
    "        class_mode='categorical',\n",
    "        batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(model_fit):\n",
    "    metrics = ['accuracy', 'precision', 'recall']\n",
    "    for i in metrics:\n",
    "        plt.plot(model_fit.history[i], label='Train')\n",
    "        plt.plot(model_fit.history[f'val_{i}'], label='Test')\n",
    "        plt.ylabel(i)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "effnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(effnet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=.0001), loss='categorical_crossentropy', metrics=['accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1e6c26adc8bad395b004c18f56e59eec4f16088a73327fc7833d1c5c445ad10"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
